{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"05wk-020: StandardScaler를 이용한 전처리\"\n",
    "author: \"최규빈\"\n",
    "date: \"10/05/2023\"\n",
    "bibliography: ref.bib\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 강의영상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{<video: https://youtu.be/playlist?list=PLQqh36zP38-zF3fkpXnSHg8H9C9VSq-vC&si=2IRrJzFgKagzxtkO >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. `StandardScaler()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 예제자료 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toeic</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>0.051535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>935</td>\n",
       "      <td>0.355496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>485</td>\n",
       "      <td>2.228435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>1.179701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>445</td>\n",
       "      <td>3.962356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65</td>\n",
       "      <td>1.846885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>290</td>\n",
       "      <td>0.309928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>730</td>\n",
       "      <td>0.336081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toeic       gpa\n",
       "0    135  0.051535\n",
       "1    935  0.355496\n",
       "2    485  2.228435\n",
       "3     65  1.179701\n",
       "4    445  3.962356\n",
       "5     65  1.846885\n",
       "6    290  0.309928\n",
       "7    730  0.336081"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/guebin/MP2023/main/posts/employment.csv').loc[:7,['toeic','gpa']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 스케일러를 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8680409 , -0.98104887],\n",
       "       [ 1.81575704, -0.73905505],\n",
       "       [ 0.3061207 ,  0.75205327],\n",
       "       [-1.10287322, -0.08287854],\n",
       "       [ 0.17193081,  2.13248542],\n",
       "       [-1.10287322,  0.44828929],\n",
       "       [-0.34805505, -0.77533368],\n",
       "       [ 1.12803382, -0.75451182]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclr = sklearn.preprocessing.StandardScaler()\n",
    "sclr.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 계산식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.868041\n",
       "1    1.815757\n",
       "2    0.306121\n",
       "3   -1.102873\n",
       "4    0.171931\n",
       "5   -1.102873\n",
       "6   -0.348055\n",
       "7    1.128034\n",
       "Name: toeic, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.toeic - df.toeic.mean())/df.toeic.std(ddof=0) # 계산식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` `MinMaxScaler`와 `StandardScaler`는 데이터의 스케일을 조정하는 두 가지 일반적인 방법이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **MinMaxScaler**:\n",
    "\n",
    "   - **작동 원리**: 데이터를 0과 1 사이의 값으로 조정\n",
    "   - **장점**: 원하는 범위 내로 데이터를 조정할 때 유용. 특히 신경망에서는 활성화 함수의 범위와 일치하도록 입력 값을 조정하는 데 유용.^[sigmoid, tanh와 같은 활성화 함수의 출력값과 맞추는 용도]\n",
    "   - **단점**: 이상치에 매우 민감하다. 이상치 때문에 전체 데이터의 스케일이 크게 영향받을 수 있음.\n",
    "\n",
    "2. **StandardScaler**:\n",
    "\n",
    "   - **작동 원리**: 데이터의 평균을 0, 표준편차를 1로 만드는 방식으로 조정.\n",
    "   - **장점**: 이상치에 MinMaxScaler보다 덜 민감함. 많은 통계적 기법들, 특히 PCA 같은 선형 알고리즘에서 잘 작동함.^[그야 PCA는 정규분포를 가정하고 만든 알고리즘이라~]\n",
    "   - **단점**: MinMaxScaler와 달리, 표준화된 데이터의 값이 특정 범위 내에 있음을 보장하지 않음.^[MinMaxScaler도 딱히 엄격하게 보장하는건 아니야]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 무식한 설명 (1)\n",
    "\n",
    "- MinMaxScaler: 컴퓨터공학과, 전자공학과 느낌 \n",
    "- StandardScaler: 통계학과 느낌 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` 무식한 설명 (2)\n",
    "\n",
    "- MinMaxScaler: 데이터가 기본적으로 0$\\sim$1 혹은 -1$\\sim$1 사이의 범위에 있다고 가정한다. \n",
    "- StandardScaler: 데이터가 기본적으로 정규분포를 따른다고 가정하는 모형들과 잘 맞는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **둘 중 어느 것을 선택할지 결정하기 위한 고려사항**:\n",
    "\n",
    "\n",
    "- 이상치가 많으면 `StandardScaler`가 더 적합할 수 있다. \n",
    "- 모델의 알고리즘과 특성에 따라 선택해야 한다. 예를 들어, 신경망은 일반적으로 0과 1 사이의 값이나 -1과 1 사이의 값으로 입력을 받는 활성화 함수를 사용하므로 `MinMaxScaler`가 적합할 수 있다. \n",
    "\n",
    "결론적으로, 두 스케일링 방법 중 어느 것이 더 좋은지는 사용 사례와 데이터의 특성에 따라 다르기 때문에, 가능한 경우 둘 다 시도해보고 모델의 성능을 비교하는 것이 좋다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-` **둘 중 어느 것을 선택할지 결정하기 위한 고려사항** -- 무식한 설명 \n",
    "\n",
    "- 보통은 아무거나 해도 큰일 안남. \n",
    "- 아주 특수한 경우^[Classical PCA]를 제외하고는 어차피 이론적인 선택기준은 없음. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
